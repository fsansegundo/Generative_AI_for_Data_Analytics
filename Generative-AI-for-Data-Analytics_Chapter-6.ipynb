{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea87f37e-7462-41d8-b66a-3dec3d83fefd",
   "metadata": {},
   "source": [
    "# 6.2 Sentiment Analysis\n",
    "\n",
    "## 6.2.3 Sentiment analysis with LLM’s API\n",
    "\n",
    "### Listing 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a4e248-e2c2-4ecd-8b04-fc03ed7fa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of reviews to analyze (prepared manually). We want to limit the analysis to the first 500 non-empty reviews to save you some time and money.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])[0:500]\n",
    "reviews = list(df[\"review_comment_message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d60d398-2673-4862-bc8f-d0915392f690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code snippet that utilizes the API for Chat-GPT-4\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Replace 'your_openai_api_key' with your actual OpenAI API key\n",
    "client = OpenAI(\n",
    "    api_key= \"your-api-key\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_sentiment(review):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"The sentiment of this review is: {review}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "    )\n",
    "    completion = response.choices[0].message.content\n",
    "    if \"positive\" in completion:\n",
    "        return \"positive\"\n",
    "    elif \"neutral\" in completion:\n",
    "        return \"neutral\"\n",
    "    elif \"negative\" in completion:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Analyze the reviews and store the output (manually adapted)\n",
    "sentiments = []\n",
    "for review in reviews:\n",
    "    sentiments.append(get_sentiment(review))\n",
    "\n",
    "df[\"GPT4\"] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "387449a3-8023-4abf-a767-d4f498845565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple keywords analysis performed in section 5.5.4 (Listing 5.6) and run on the set of the first 500 reviews.\n",
    "keywords = [\n",
    "    \"excelente\", \"ótimo\", \"maravilhoso\", \"incrível\", \"fantástico\",\n",
    "    \"perfeito\", \"bom\", \"eficiente\", \"durável\", \"confiável\",\n",
    "    \"rápido\", \"custo-benefício\", \"recomendo\", \"satisfeito\",\n",
    "    \"surpreendente\", \"confortável\", \"fácil de usar\", \"funcional\",\n",
    "    \"melhor\", \"vale a pena\"\n",
    "]\n",
    "\n",
    "# Second version of the keyword search function proposed by ChatGPT that copes with NaNs in the input.\n",
    "def is_positive(review, keywords):\n",
    "    if not isinstance(review, str):\n",
    "        return False\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in review.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Applying the function to the test DataFrame (adapted).\n",
    "df['keyword_sentiment'] = df['review_comment_message'].apply(lambda x: is_positive(x, keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc7bf10-ebad-4b66-883e-8506016a8d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the basic keyword search:\n",
      "Sensitivity:  0.45\n",
      "Specificity:  0.9\n",
      "Quality of the GPT-4 direct sentiment analysis:\n",
      "Sensitivity:  0.74\n",
      "Specificity:  0.93\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis based on keywords.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['keyword_sentiment']==True]\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the basic keyword search:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "###\n",
    "# Assessing quality of the sentiment analysis based on ChatGPT-4 language model.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['GPT4']=='positive']\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the GPT-4 direct sentiment analysis:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec73a744-6038-4973-afd2-5749e10122cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review score:\n",
      "5    249\n",
      "1    106\n",
      "4     71\n",
      "3     51\n",
      "2     23\n",
      "Name: review_score, dtype: int64\n",
      "\n",
      "Keyword sentiment analysis:\n",
      "False    337\n",
      "True     163\n",
      "Name: keyword_sentiment, dtype: int64\n",
      "\n",
      "GPT4 sentiment analysis:\n",
      "positive    250\n",
      "unknown     165\n",
      "negative     78\n",
      "neutral       7\n",
      "Name: GPT4, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Printing out the number of positive, negative and unknown/neutral annotations\n",
    "print(\"\\nReview score:\")\n",
    "print(df[\"review_score\"].value_counts())\n",
    "print(\"\\nKeyword sentiment analysis:\")\n",
    "print(df[\"keyword_sentiment\"].value_counts())\n",
    "print(\"\\nGPT4 sentiment analysis:\")\n",
    "print(df[\"GPT4\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52237246-89ba-451e-aa55-377f0bff9c8c",
   "metadata": {},
   "source": [
    "## 6.2.5 Sentiment analysis with a suboptimal model\n",
    "### Listing 6.2\n",
    "\n",
    "The code proposed by ChatGPT works well. The correct label for positive reviews was added manually based on the FinBERT-PT-BR model documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1c03bc-abe5-42a7-a421-edcf72318a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Assuming df is your DataFrame and it has a column named 'review_comment_message'\n",
    "\n",
    "# Load the sentiment analysis pipeline with the FinBERT-PT-BR model\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"lucas-leme/FinBERT-PT-BR\")\n",
    "\n",
    "def get_sentiment(review):\n",
    "    try:\n",
    "        result = classifier(review)[0]\n",
    "        return result['label'], result['score']\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the sentiment analysis to each review\n",
    "df['sentiment'], df['score'] = zip(*df['review_comment_message'].map(get_sentiment))\n",
    "\n",
    "# Filter the DataFrame to only include positive reviews\n",
    "positive_reviews_df = df[df['sentiment'] == 'POSITIVE']  # Adjust label as necessary based on model output\n",
    "\n",
    "# Now positive_reviews_df contains only the positive reviews\n",
    "\n",
    "# Clean the df dataframe (manually added)\n",
    "df = df.drop(['sentiment', 'score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894849da-bad1-4ec1-aa61-63b452ded976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the FinBERT-PT-BR sentiment analysis:\n",
      "Sensitivity:  0.56\n",
      "Specificity:  0.93\n",
      "Nr of reviews classified as positive:  193\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis based on FinBERT-PT-BR model.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = positive_reviews_df\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the FinBERT-PT-BR sentiment analysis:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "print(\"Nr of reviews classified as positive: \", len(positive_reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372414c-2de4-4b4c-8a91-e4062bc2b959",
   "metadata": {},
   "source": [
    "## 6.2.6 Sentiment analysis on translated inputs\n",
    "### Listing 6.3\n",
    "The code translates the Portuguese input to English using Meta m2m100_418M model. It utilizes the distilbert-base-uncased-finetuned-sst-2-english model for sentiment analysis. The part to assess the output quality was added manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a88e80-67e5-40e9-8fd1-2d2e150f0e12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer, pipeline\n",
    "\n",
    "# Assuming df is your DataFrame and it has a column named 'review_comment_message'\n",
    "\n",
    "# Initialize the M2M100 tokenizer and model for translation\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "# Initialize the sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "def translate_review(review):\n",
    "    # Specify the source and target language\n",
    "    tokenizer.src_lang = \"pt\"\n",
    "    encoded_pt = tokenizer(review, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**encoded_pt, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "    translated_review = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_review\n",
    "\n",
    "def analyze_sentiment(review):\n",
    "    result = sentiment_pipeline(review)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Translate reviews from Portuguese to English\n",
    "df['translated_review'] = df['review_comment_message'].apply(translate_review)\n",
    "\n",
    "# Apply sentiment analysis to the translated reviews\n",
    "df['sentiment'], df['score'] = zip(*df['translated_review'].apply(analyze_sentiment))\n",
    "\n",
    "# Filter the DataFrame to only include reviews with positive sentiment\n",
    "positive_reviews_df = df[df['sentiment'] == 'POSITIVE']\n",
    "\n",
    "# positive_reviews_df now contains only the positive reviews, translated into English\n",
    "\n",
    "# Clean the df dataframe (manually added)\n",
    "df = df.drop(['sentiment', 'score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4577936f-0889-4c4a-868c-4d9908b6d634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the sentiment analysis with English translations:\n",
      "Sensitivity:  0.86\n",
      "Specificity:  0.89\n",
      "Nr of reviews classified as positive:  295\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis with a translated input and classifier for English.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = positive_reviews_df\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the sentiment analysis with English translations:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "print(\"Nr of reviews classified as positive: \", len(positive_reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b308a-1985-44f8-9685-461f031b96dc",
   "metadata": {},
   "source": [
    "## 6.2.7 Sentiment analysis with multilingual models\n",
    "### Listing 6.4\n",
    "The code utilizes the multilingual model to assess sentiment of the reviews. The code required manual adaptation of the label used for positive reviews. The part for checking the quality of the output was added manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7786a3-4faa-41e0-be11-58a7768e6291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Assuming df is your DataFrame and it has a column named 'review_comment_message'\n",
    "\n",
    "# Initialize the sentiment analysis pipeline with the multilingual model\n",
    "sentiment_pipeline = pipeline('sentiment-analysis', model='cardiffnlp/twitter-xlm-roberta-base-sentiment')\n",
    "\n",
    "def analyze_sentiment_multilingual(text):\n",
    "    result = sentiment_pipeline(text)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Apply sentiment analysis to the reviews\n",
    "df['sentiment'], df['score'] = zip(*df['review_comment_message'].apply(analyze_sentiment_multilingual))\n",
    "\n",
    "# Filter the DataFrame to only include positive reviews\n",
    "# Note: The labels returned by this model are 'LABEL_0' (negative), 'LABEL_1' (neutral), and 'LABEL_2' (positive).\n",
    "positive_reviews_df = df[df['sentiment'] == 'positive']  # Addapted manually\n",
    "\n",
    "# positive_reviews_df now contains only the reviews classified as positive\n",
    "\n",
    "# Clean the df dataframe (manually added)\n",
    "df = df.drop(['sentiment', 'score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470e959d-c9f1-4b97-bcb4-6eb8fa25f20c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the sentiment analysis with a multilingual model:\n",
      "Sensitivity:  0.79\n",
      "Specificity:  0.93\n",
      "Nr of reviews classified as positive:  265\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis with a multilingual model.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = positive_reviews_df\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the sentiment analysis with a multilingual model:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "print(\"Nr of reviews classified as positive: \", len(positive_reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e51ec1-7df9-489b-a061-1805fb8d8781",
   "metadata": {},
   "source": [
    "## 6.2.8 Sentiment analysis with zero-shot learning models\n",
    "### Listing 6.5\n",
    "The code utilizes a zero-shot learning model proposed by Generative AI to assess sentiment of the reviews. The code required manual adaptation to our input data. The part for checking the quality of the output was added manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5455ef53-5bc9-4497-8135-ec81b47b2036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Specify the candidate labels\n",
    "candidate_labels = [\"positive\", \"negative\"]\n",
    "\n",
    "# Define a function to classify a single review\n",
    "def classify_review(review):\n",
    "    result = classifier(review, candidate_labels=candidate_labels, hypothesis_template=\"This review is {}.\", multi_label=False)\n",
    "    return result['labels'][0]\n",
    "\n",
    "# Apply the classification to each review\n",
    "df['sentiment'] = df['review_comment_message'].apply(classify_review)\n",
    "\n",
    "# Filter the DataFrame to only include positive reviews\n",
    "positive_reviews_df = df[df['sentiment'] == 'positive']\n",
    "\n",
    "# Clean the df dataframe (manually added)\n",
    "df = df.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75620348-f346-481d-818e-63b872c3b1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality of the sentiment analysis with a zero-shot learning model:\n",
      "Sensitivity:  0.87\n",
      "Specificity:  0.74\n",
      "Nr of reviews classified as positive:  325\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis with a zero-shot learning model\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = positive_reviews_df\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality of the sentiment analysis with a zero-shot learning model:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "print(\"Nr of reviews classified as positive: \", len(positive_reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8d015-115f-4dea-948f-fab68ffd9a05",
   "metadata": {},
   "source": [
    "# 6.3 Text summarization\n",
    "## 6.3.4 Summarizing text with dedicated libraries\n",
    "### Listing 6.6\n",
    "\n",
    "Python code utilizing the frequency-based approach to generate summaries of very short customer reviews in Portuguese. Proposed by ChatGPT. The input was adapted manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48300746-bf48-4875-a852-9adae2a4afc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\marle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marle\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest review: NÃO RECEBI O PRODUTO, O PRODUTO CONSTA COMO ENVIADO PARA O CORREIO DE RIBEIRÃO PRETO. O CORREIO NÃO RECEBEU O PRODUTO. ENVIE VARIAS MENSAGEM PARA A targaryen E NÃO OBTIVE. ESTA targaryen ESTA SUJANDO SEU NOME\n",
      "Summary: produto correio targaryen\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample data (manually adapted to remove empty records)\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])\n",
    "\n",
    "# Function to tokenize and remove stopwords\n",
    "def preprocess(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in string.punctuation and token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "# Function to create word frequency distribution\n",
    "def word_frequency(tokens):\n",
    "    frequency = Counter(tokens)\n",
    "    return frequency\n",
    "\n",
    "# Function to summarize short reviews\n",
    "def summarize_reviews(text, num_keywords=3):\n",
    "    tokens = preprocess(text)\n",
    "    frequency = word_frequency(tokens)\n",
    "    important_words = [word for word, count in frequency.most_common(num_keywords)]\n",
    "    summary = ' '.join(important_words)\n",
    "    return summary\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['summary'] = df['review_comment_message'].apply(summarize_reviews)\n",
    "\n",
    "# Display the results (manually adapted to print the summary of the longest message)\n",
    "print(\"Longest review:\", df.loc[1316][\"review_comment_message\"])\n",
    "print(\"Summary:\", df.loc[1316][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02869abd-56e3-457f-9727-7d8cef468073",
   "metadata": {},
   "source": [
    "## 6.3.5 Topic modeling\n",
    "### Listing 6.7\n",
    "\n",
    "Python code proposed by ChatGPT to perform topic modelling of negative customer reviews in Portuguese. The code was manually adapted to our input data. Only negative reviews with review_scores of 1 or 2 were used in the analysis. The output was manually adapted to display 7 words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d8c5378-92f9-4d0b-a90c-7de717a73bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.055*\"compr\" + 0.043*\"receb\" + 0.032*\"produt\" + 0.020*\"2\" + 0.019*\"entreg\" + 0.017*\"apen\" + 0.017*\"ped\"\n",
      "\n",
      "Topic 2: 0.043*\"entreg\" + 0.035*\"produt\" + 0.035*\"compr\" + 0.028*\"receb\" + 0.021*\"agor\" + 0.020*\"praz\" + 0.013*\"falt\"\n",
      "\n",
      "Topic 3: 0.095*\"produt\" + 0.046*\"receb\" + 0.021*\"entreg\" + 0.017*\"compr\" + 0.016*\"aind\" + 0.016*\"vei\" + 0.015*\"quer\"\n",
      "\n",
      "Topic 4: 0.070*\"produt\" + 0.066*\"entreg\" + 0.040*\"cheg\" + 0.024*\"aind\" + 0.024*\"dia\" + 0.023*\"praz\" + 0.019*\"receb\"\n",
      "\n",
      "Topic 5: 0.052*\"produt\" + 0.035*\"receb\" + 0.035*\"compr\" + 0.032*\"vei\" + 0.017*\"nao\" + 0.012*\"cheg\" + 0.011*\"entreg\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "# Load data. Only negative reviews were chosen for the analysis (adapted manually).\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])\n",
    "df = df[(df[\"review_score\"]==1) | (df[\"review_score\"]==2)]\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text, language='portuguese'):\n",
    "    # Remove special characters, convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "    # Tokenize words\n",
    "    words = word_tokenize(cleaned_text, language=language)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "df['preprocessed_reviews'] = df['review_comment_message'].apply(preprocess_text)\n",
    "\n",
    "# Loading the model.\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = Dictionary(df['preprocessed_reviews'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['preprocessed_reviews']]\n",
    "\n",
    "# Train an LDA model\n",
    "num_topics = 5  # Adjust this value according to the desired number of topics\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
    "\n",
    "# Displaying results (manually adapted to display 7 words).\n",
    "def display_topics(model, num_topics, num_words=7):\n",
    "    for idx, topic in model.print_topics(num_topics, num_words):\n",
    "        print(f\"Topic {idx + 1}: {topic}\\n\")\n",
    "\n",
    "display_topics(lda_model, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21aed7b-d6ce-440c-9cb9-bceaa1684665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
