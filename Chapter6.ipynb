{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea87f37e-7462-41d8-b66a-3dec3d83fefd",
   "metadata": {},
   "source": [
    "# 6.2 Sentiment Analysis\n",
    "\n",
    "## 6.2.2 Sentiment analysis with ChatGPT API\n",
    "\n",
    "### Let’s ask ChatGPT 6.2\n",
    "\n",
    "Query: How to perform sentiment analysis of customer reviews using your API?\n",
    "\n",
    "Output: ChatGPT's working code to generate text completion and extracting the sentiment from the output. The code was manually adapted to load custom data and store the output in the more convinient way. It was assumed that the input file is stored in the same folder as this notebook. For the purpose of our analysis only the first 500 reviews were analysed from the exemplary DataFrame. The first code snippet utilizes the \"text-davinci-003\" engine, the second utilizes the \"text-davinci-002\" engine. The results of both engines are compared below with the results of sentiment analysis done with help of the basic keyword search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98a4e248-e2c2-4ecd-8b04-fc03ed7fa4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of reviews to analyze (adapted manually)\n",
    "import pandas as pd\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])[0:500]\n",
    "reviews = list(df[\"review_comment_message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdf06b2-2060-4ef5-8a78-55105978a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippet that utilizes the text-davinci-003 engine\n",
    "\n",
    "import openai\n",
    "\n",
    "# Replace 'your_openai_api_key' with your actual OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "def get_sentiment(review):\n",
    "    prompt = f\"The sentiment of this review is: {review} -> \"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=10,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    completion = response.choices[0].text.strip()\n",
    "    if \"positive\" in completion:\n",
    "        return \"positive\"\n",
    "    elif \"neutral\" in completion:\n",
    "        return \"neutral\"\n",
    "    elif \"negative\" in completion:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Analyze the reviews and store the output (manually adapted)\n",
    "sentiments = []\n",
    "for review in reviews:\n",
    "    sentiments.append(get_sentiment(review))\n",
    "\n",
    "df[\"GPT_003_sentiment\"] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255ad36-b9f9-448a-8633-b8dc1cae013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippet that utilizes the text-davinci-002 engine\n",
    "\n",
    "import openai\n",
    "\n",
    "# Replace 'your_openai_api_key' with your actual OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "def get_sentiment(review):\n",
    "    prompt = f\"The sentiment of this review is: {review} -> \"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=10,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    completion = response.choices[0].text.strip()\n",
    "    if \"positive\" in completion:\n",
    "        return \"positive\"\n",
    "    elif \"neutral\" in completion:\n",
    "        return \"neutral\"\n",
    "    elif \"negative\" in completion:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Analyze the reviews and store the output (manually adapted)\n",
    "sentiments = []\n",
    "for review in reviews:\n",
    "    sentiments.append(get_sentiment(review))\n",
    "\n",
    "df[\"GPT_002_sentiment\"] = sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387449a3-8023-4abf-a767-d4f498845565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple keywords analysis performed in section 5.6.2 run on the set of the first 500 reviews.\n",
    "keywords = [\n",
    "    \"excelente\", \"ótimo\", \"maravilhoso\", \"incrível\", \"fantástico\",\n",
    "    \"perfeito\", \"bom\", \"eficiente\", \"durável\", \"confiável\",\n",
    "    \"rápido\", \"custo-benefício\", \"recomendo\", \"satisfeito\",\n",
    "    \"surpreendente\", \"confortável\", \"fácil de usar\", \"funcional\",\n",
    "    \"melhor\", \"vale a pena\"\n",
    "]\n",
    "\n",
    "# Second version of the keyword search function proposed by ChatGPT that copes with NaNs in the input.\n",
    "def is_positive(review, keywords):\n",
    "    if not isinstance(review, str):\n",
    "        return False\n",
    "\n",
    "    for keyword in keywords:\n",
    "        if keyword.lower() in review.lower():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Applying the function to the test DataFrame (adapted).\n",
    "df['keyword_sentiment'] = df['review_comment_message'].apply(lambda x: is_positive(x, keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7bf10-ebad-4b66-883e-8506016a8d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis based on keywords.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['keyword_sentiment']==True]\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality for basic keyword search:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "###\n",
    "# Assessing quality of the sentiment analysis based on ChatGPT language model text-davinci-003.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['GPT_003_sentiment']=='positive']\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality for GPT direct sentiment analysis with text-davinci-003:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))\n",
    "\n",
    "###\n",
    "# Assessing quality of the sentiment analysis based on ChatGPT language model text-davinci-002.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['GPT_002_sentiment']=='positive']\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality for GPT direct sentiment analysis with text-davinci-002:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73a744-6038-4973-afd2-5749e10122cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the number of positive, negative and unknown/neutral annotations\n",
    "print(\"\\nReview score:\")\n",
    "print(df[\"review_score\"].value_counts())\n",
    "print(\"\\nKeyword sentiment analysis:\")\n",
    "print(df[\"keyword_sentiment\"].value_counts())\n",
    "print(\"\\nGPT_003 sentiment analysis:\")\n",
    "print(df[\"GPT_003_sentiment\"].value_counts())\n",
    "print(\"\\nGPT_002 sentiment analysis:\")\n",
    "print(df[\"GPT_002_sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52237246-89ba-451e-aa55-377f0bff9c8c",
   "metadata": {},
   "source": [
    "## 6.2.3 Sentiment analysis with a pretrained model\n",
    "### Let’s ask ChatGPT 6.3\n",
    "\n",
    "Query: How to perform sentiment analysis of Portuguese customer reviews in Python?\n",
    "\n",
    "Output: The code proposed by ChatGPT required small debugging, but after pasting the error message to ChatGPT it was able to come out with a correct solution. The code works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67757e29-53e0-4282-bd34-b5d8b9cd7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import unidecode\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from translate import Translator\n",
    "\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = unidecode.unidecode(text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens\n",
    "\n",
    "class PortugueseTextBlob(TextBlob):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PortugueseTextBlob, self).__init__(*args, **kwargs)\n",
    "        self.translator = Translator(to_lang=\"en\")\n",
    "\n",
    "    def translate_to_english(self, text):\n",
    "        try:\n",
    "            return self.translator.translate(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Translation error: {e}\")\n",
    "            return text\n",
    "\n",
    "    def sentiment(self, translated_text):\n",
    "        tb = TextBlob(translated_text, analyzer=NaiveBayesAnalyzer())\n",
    "        return tb.sentiment\n",
    "    \n",
    "review = \"Eu realmente gostei deste produto!\"\n",
    "tokens = preprocess(review)\n",
    "review_clean = ' '.join(tokens)\n",
    "pt_blob = PortugueseTextBlob(review_clean)\n",
    "translated_text = pt_blob.translate_to_english(review_clean)\n",
    "sentiment = pt_blob.sentiment(translated_text)\n",
    "\n",
    "print(\"Sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ce585-f1b3-4d8f-bd79-05a9b2c61a7a",
   "metadata": {},
   "source": [
    "### Let’s ask ChatGPT 6.4\n",
    "Query: Adapt this code to analyze reviews stored in a pandas DataFrame column. The output should be stored as a new DataFrame column with values: \"positive\", \"negative\" or \"neutral\".\n",
    "\n",
    "Output: Works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaa8be-a5b8-4594-bd68-827b9cf846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_sentiment(review):\n",
    "    tokens = preprocess(review)\n",
    "    review_clean = ' '.join(tokens)\n",
    "    pt_blob = PortugueseTextBlob(review_clean)\n",
    "    translated_text = pt_blob.translate_to_english(review_clean)\n",
    "    sentiment = pt_blob.sentiment(translated_text)\n",
    "\n",
    "    if sentiment.classification == 'pos' and sentiment.p_pos >= 0.6:\n",
    "        return 'positive'\n",
    "    elif sentiment.classification == 'neg' and sentiment.p_neg >= 0.6:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Loading testing data - added manually\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])[0:500]\n",
    "\n",
    "# Running the analysis - adapted manually\n",
    "df['pretrained_sentiment'] = df['review_comment_message'].apply(analyze_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8b1f3-658b-4845-a2e7-e4ef23c125a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# Assessing quality of the sentiment analysis done with a pretrained language model.\n",
    "\n",
    "# Extract records with positive reviews assessed by sentiment analysis and by review scores.\n",
    "posrev_senti = df[df['pretrained_sentiment']=='positive']\n",
    "posrev_score = df[(df['review_score']==5)|(df['review_score']==4)]\n",
    "\n",
    "# Perform set operations to determine true positives (TP), false positives (FP), false negatives (FN) and true negatives (TN).\n",
    "TP = pd.merge(posrev_senti, posrev_score)\n",
    "FP = posrev_senti[posrev_senti[\"review_id\"].isin(posrev_score[\"review_id\"]) == False]\n",
    "FN = posrev_score[posrev_score[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False]\n",
    "TN = df[(df[\"review_id\"].isin(posrev_senti[\"review_id\"]) == False) & (df[\"review_id\"].isin(posrev_score[\"review_id\"]) == False)]\n",
    "\n",
    "# Calculate sensitivity and specificity\n",
    "print(\"Quality for the sentiment analysis done with a pretrained model:\")\n",
    "print(\"Sensitivity: \", round(len(TP) / (len(TP) + len(FN)),2))\n",
    "print(\"Specificity: \", round(len(TN) / (len(TN) + len(FP)),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8d015-115f-4dea-948f-fab68ffd9a05",
   "metadata": {},
   "source": [
    "# 6.3 Text summarization\n",
    "## 6.3.2 Summarizing text with dedicated libraries\n",
    "### Let's ask ChatGPT 6.7\n",
    "\n",
    "Query: Provide Python code to generate summaries of very short customer reviews in Portuguese. Use frequency-based approach.\n",
    "\n",
    "Output: The code works well. The input was adapted manually to remove empty records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48300746-bf48-4875-a852-9adae2a4afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample data (manually adapted to remove empty records)\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])\n",
    "\n",
    "# Function to tokenize and remove stopwords\n",
    "def preprocess(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in string.punctuation and token not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "# Function to create word frequency distribution\n",
    "def word_frequency(tokens):\n",
    "    frequency = Counter(tokens)\n",
    "    return frequency\n",
    "\n",
    "# Function to summarize short reviews\n",
    "def summarize_reviews(text, num_keywords=3):\n",
    "    tokens = preprocess(text)\n",
    "    frequency = word_frequency(tokens)\n",
    "    important_words = [word for word, count in frequency.most_common(num_keywords)]\n",
    "    summary = ' '.join(important_words)\n",
    "    return summary\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['summary'] = df['review_comment_message'].apply(summarize_reviews)\n",
    "\n",
    "# Display the results (manually adapted to print the summary of the longest message)\n",
    "print(\"Longest review:\", df.loc[1316][\"review_comment_message\"])\n",
    "print(\"Summary:\", df.loc[1316][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02869abd-56e3-457f-9727-7d8cef468073",
   "metadata": {},
   "source": [
    "## 6.3.3 Topic modeling\n",
    "### Let’s ask ChatGPT 6.8\n",
    "\n",
    "Query: I have a set of short negative customer reviews in Portuguese stored in a pandas dataframe column. I want to know what are the main concerns raised by customers. How to extract this information from reviews using text summarization?\n",
    "\n",
    "Output: Code works well. The code was manually adapted to our input data. Only negative reviews with review_scores of 1 or 2 were used in the analysis. The output was manually adapted to display 7 words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c5378-92f9-4d0b-a90c-7de717a73bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "\n",
    "# Load your DataFrame (assuming your reviews are in the 'review_comment_message' column)\n",
    "# Only negative reviews were chosen for the analysis (adapted manually).\n",
    "df = pd.read_csv('olist_order_reviews_dataset.csv')\n",
    "df = df.dropna(subset = ['review_comment_message'])\n",
    "df = df[(df[\"review_score\"]==1) | (df[\"review_score\"]==2)]\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text, language='portuguese'):\n",
    "    # Remove special characters, convert to lowercase\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "    # Tokenize words\n",
    "    words = word_tokenize(cleaned_text, language=language)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(language))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "df['preprocessed_reviews'] = df['review_comment_message'].apply(preprocess_text)\n",
    "\n",
    "# Loading the model.\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = Dictionary(df['preprocessed_reviews'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['preprocessed_reviews']]\n",
    "\n",
    "# Train an LDA model\n",
    "num_topics = 5  # Adjust this value according to the desired number of topics\n",
    "lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
    "\n",
    "# Displaying results (manually adapted to display 7 words).\n",
    "def display_topics(model, num_topics, num_words=7):\n",
    "    for idx, topic in model.print_topics(num_topics, num_words):\n",
    "        print(f\"Topic {idx + 1}: {topic}\\n\")\n",
    "\n",
    "display_topics(lda_model, num_topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
